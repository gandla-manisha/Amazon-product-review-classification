{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OqEP1SlGeVZ"
      },
      "source": [
        "# SAM: Inference Playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dE2hzjSNQs0p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'SAM'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbaMZ40hQxT0",
        "outputId": "0c105988-483a-4b89-a686-64611371ea61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SAM'...\n",
            "remote: Enumerating objects: 228, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 228 (delta 32), reused 22 (delta 22), pack-reused 180 (from 1)\u001b[K\n",
            "Receiving objects: 100% (228/228), 24.63 MiB | 11.96 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yuval-alaluf/SAM.git $CODE_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43F-3KfeQ08S",
        "outputId": "0ec6aecd-46ad-4af3-9ba7-3f346281d7a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-02 02:58:58--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250202%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250202T025859Z&X-Amz-Expires=300&X-Amz-Signature=a9338ff8a2d57a2b20b18db1aa1c1353da7b2736613bfc85fb9908a8ef7d961c&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-02 02:58:59--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250202%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250202T025859Z&X-Amz-Expires=300&X-Amz-Signature=a9338ff8a2d57a2b20b18db1aa1c1353da7b2736613bfc85fb9908a8ef7d961c&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip’\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-02-02 02:58:59 (4.07 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "  inflating: /usr/local/bin/ninja    \n",
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "av0207x4Q2iL"
      },
      "outputs": [],
      "source": [
        "os.chdir(f'./{CODE_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Zvwx9NsiQq9t",
        "outputId": "20963b56-1c5c-40c8-9156-979883f0ff7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "/root/.cache/torch_extensions/py311_cu124/fused/fused.so: cannot open shared object file: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-083f4721ea2a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgeTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor2im\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpSp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/SAM/models/psp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpsp_encoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstylegan2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SAM/models/encoders/psp_encoders.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_IR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_IR_SE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstylegan2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEqualLinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SAM/models/stylegan2/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstylegan2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFusedLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfused_leaky_relu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SAM/models/stylegan2/op/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfused_act\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFusedLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfused_leaky_relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mupfirdn2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SAM/models/stylegan2/op/fused_act.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m fused = load(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;34m'fused'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     sources=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1312\u001b[0m         ...     verbose=True)\n\u001b[1;32m   1313\u001b[0m     \"\"\"\n\u001b[0;32m-> 1314\u001b[0;31m     return _jit_compile(\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_exec_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1746\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_import_module_from_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_python_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_import_module_from_library\u001b[0;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_from_file_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2140\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2141\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: /root/.cache/torch_extensions/py311_cu124/fused/fused.so: cannot open shared object file: No such file or directory",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from argparse import Namespace\n",
        "import os\n",
        "import sys\n",
        "import pprint\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from datasets.augmentations import AgeTransformer\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uj3dJjQsQq9y"
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_TYPE = 'ffhq_aging'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mStxrAtuQq9y"
      },
      "source": [
        "## Step 1: Download Pretrained Model\n",
        "As part of this repository, we provide our pretrained aging model.\n",
        "We'll download the model for the selected experiments as save it to the folder `../pretrained_models`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pC38oLGQq9z"
      },
      "outputs": [],
      "source": [
        "def get_download_model_command(file_id, file_name):\n",
        "    \"\"\" Get wget download command for downloading the desired model and save to directory ../pretrained_models. \"\"\"\n",
        "    current_directory = os.getcwd()\n",
        "    save_path = os.path.join(os.path.dirname(current_directory), \"pretrained_models\")\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
        "    return url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOQ2Vz2kQq9z"
      },
      "outputs": [],
      "source": [
        "MODEL_PATHS = {\n",
        "    \"ffhq_aging\": {\"id\": \"1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC\", \"name\": \"sam_ffhq_aging.pt\"}\n",
        "}\n",
        "\n",
        "path = MODEL_PATHS[EXPERIMENT_TYPE]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0nHPvo5Qq9z"
      },
      "outputs": [],
      "source": [
        "!wget {download_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvRDiRrMQq90"
      },
      "source": [
        "## Step 2: Define Inference Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNaSSzZsQq90"
      },
      "source": [
        "Below we have a dictionary defining parameters such as the path to the pretrained model to use and the path to the\n",
        "image to perform inference on.\n",
        "While we provide default values to run this script, feel free to change as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaGqalwuQq90"
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_DATA_ARGS = {\n",
        "    \"ffhq_aging\": {\n",
        "        \"model_path\": \"../pretrained_models/sam_ffhq_aging.pt\",\n",
        "        \"image_path\": \"notebooks/images/866.jpg\",\n",
        "        \"transform\": transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjkLqLkDQq90"
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[EXPERIMENT_TYPE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkfqoKJwQq91"
      },
      "source": [
        "## Step 3: Load Pretrained Model\n",
        "We assume that you have downloaded the pretrained aging model and placed it in the path defined above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZuho98JQq91"
      },
      "outputs": [],
      "source": [
        "model_path = EXPERIMENT_ARGS['model_path']\n",
        "ckpt = torch.load(model_path, map_location='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6NOxONxQq91"
      },
      "outputs": [],
      "source": [
        "opts = ckpt['opts']\n",
        "pprint.pprint(opts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6c93qE9Qq91"
      },
      "outputs": [],
      "source": [
        "# update the training options\n",
        "opts['checkpoint_path'] = model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRTfKFrkQq91"
      },
      "outputs": [],
      "source": [
        "opts = Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6BegCirQq92"
      },
      "source": [
        "## Step 4: Visualize Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc4Sr31TQq92"
      },
      "outputs": [],
      "source": [
        "image_path = EXPERIMENT_DATA_ARGS[EXPERIMENT_TYPE][\"image_path\"]\n",
        "original_image = Image.open(image_path).convert(\"RGB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKA9BO9_Qq92"
      },
      "outputs": [],
      "source": [
        "original_image.resize((256, 256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3a50tAcQq92"
      },
      "source": [
        "## Step 5: Perform Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6oqf8JwzK0K"
      },
      "source": [
        "### Align Image\n",
        "\n",
        "Before running inference we'll run alignment on the input image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y244_ejy9Drx"
      },
      "outputs": [],
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ9Ce1aYzmFF"
      },
      "outputs": [],
      "source": [
        "def run_alignment(image_path):\n",
        "    import dlib\n",
        "    from scripts.align_all_parallel import align_face\n",
        "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "    aligned_image = align_face(filepath=image_path, predictor=predictor)\n",
        "    print(\"Aligned image has shape: {}\".format(aligned_image.size))\n",
        "    return aligned_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTZcKMdK8y77"
      },
      "outputs": [],
      "source": [
        "aligned_image = run_alignment(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUBAfodh5PaM"
      },
      "outputs": [],
      "source": [
        "aligned_image.resize((256, 256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMyoh4X1HYAS"
      },
      "source": [
        "### Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkzQpi1aQq92"
      },
      "outputs": [],
      "source": [
        "img_transforms = EXPERIMENT_ARGS['transform']\n",
        "input_image = img_transforms(aligned_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI7yWNPDQq92"
      },
      "outputs": [],
      "source": [
        "# we'll run the image on multiple target ages\n",
        "target_ages = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "age_transformers = [AgeTransformer(target_age=age) for age in target_ages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLP4pF-2Qq93"
      },
      "outputs": [],
      "source": [
        "def run_on_batch(inputs, net):\n",
        "    result_batch = net(inputs.to(\"cuda\").float(), randomize_noise=False, resize=False)\n",
        "    return result_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfrY_gEEQq93"
      },
      "outputs": [],
      "source": [
        "# for each age transformed age, we'll concatenate the results to display them side-by-side\n",
        "results = np.array(aligned_image.resize((1024, 1024)))\n",
        "for age_transformer in age_transformers:\n",
        "    print(f\"Running on target age: {age_transformer.target_age}\")\n",
        "    with torch.no_grad():\n",
        "        input_image_age = [age_transformer(input_image.cpu()).to('cuda')]\n",
        "        input_image_age = torch.stack(input_image_age)\n",
        "        result_tensor = run_on_batch(input_image_age, net)[0]\n",
        "        result_image = tensor2im(result_tensor)\n",
        "        results = np.concatenate([results, result_image], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFgwfLTKQq93"
      },
      "source": [
        "### Visualize Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpwyrv0iQq93"
      },
      "outputs": [],
      "source": [
        "results = Image.fromarray(results)\n",
        "results   # this is a very large image (11*1024 x 1024) so it may take some time to display!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sL7fHp9Qq93",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# save image at full resolution\n",
        "results.save(\"notebooks/images/age_transformed_image.jpg\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "inference_playground.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}